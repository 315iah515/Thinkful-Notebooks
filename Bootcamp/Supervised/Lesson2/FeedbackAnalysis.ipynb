{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinkful Bootcamp Course\n",
    "\n",
    "Author: Ian Heaton\n",
    "\n",
    "Email: iheaton@gmail.com\n",
    "\n",
    "Mentor: Nemanja Radojkovic\n",
    "\n",
    "Date: 2017/03/21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "sb.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Naive Bayes Classifier to look at Yelp Feedback  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/media/ianh/space/ThinkfulData/SentimentSentencesData/yelp_labelled.xlsx\"\n",
    "messages = pd.read_excel(open(file,'rb'), sheetname='yelp_labelled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing data points for message : 0\n",
      "The number of missing data points for result  : 0\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of missing data points for message : %d\" % (sum(messages.message.isnull())))\n",
    "print(\"The number of missing data points for result  : %d\" % (sum(messages.result.isnull())))\n",
    "print(messages.result.value_counts() / messages.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>17</th>\n",
       "      <th>1979</th>\n",
       "      <th>20</th>\n",
       "      <th>2007</th>\n",
       "      <th>30</th>\n",
       "      <th>30s</th>\n",
       "      <th>35</th>\n",
       "      <th>...</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yucky</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  100  12  17  1979  20  2007  30  30s  35  ...   years  yellow  yet  \\\n",
       "0   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "1   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "2   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "3   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "4   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "\n",
       "   you  your  yourself  yucky  yum  yummy  zero  \n",
       "0    0     0         0      0    0      0     0  \n",
       "1    0     1         0      0    0      0     0  \n",
       "2    0     0         0      0    0      0     0  \n",
       "3    2     0         0      0    0      0     0  \n",
       "4    0     0         0      0    0      0     0  \n",
       "\n",
       "[5 rows x 1728 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages.message, messages.result, random_state=42)\n",
    "vect = CountVectorizer()\n",
    "train_matrix = vect.fit_transform(X_train)\n",
    "test_matrix = vect.transform(X_test)\n",
    "\n",
    "#Take a look at the resulting dataframe for training data\n",
    "pd.DataFrame(train_matrix.toarray(), columns=vect.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building With Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#Create model\n",
    "bnb = BernoulliNB()\n",
    "# fit it to our training set\n",
    "bnb.fit(train_matrix, y_train)\n",
    "# make predictions on test data using test_dtm\n",
    "predictions = bnb.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  71.60%\n",
      "\n",
      "Confusion Matrix : \n",
      " [[80 48]\n",
      " [23 99]]\n"
     ]
    }
   ],
   "source": [
    "# compare predictions to true results\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy of the model is:  {:.2f}%\\n\".format(100 * metrics.accuracy_score(y_test, predictions)))\n",
    "print(\"Confusion Matrix : \\n\", metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our null accuracy was 50 % while our accuracy after using the classifier is at  72 %.\n",
    "But our model has rather poor sensitivity and specificity with 48 messages being falsely classified as negative messages and 23 messages as being falsely classified as positive.  Perhaps Bayes classification is not the best model for the dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
