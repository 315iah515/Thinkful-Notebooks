{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinkful Bootcamp Course\n",
    "\n",
    "Author: Ian Heaton\n",
    "\n",
    "Email: iheaton@gmail.com\n",
    "\n",
    "Mentor: Nemanja Radojkovic\n",
    "\n",
    "Date: 2017/03/30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "sb.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Naive Bayes Classifier to look at Yelp Feedback "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"/media/ianh/space/ThinkfulData/SentimentSentencesData/yelp_labelled.xlsx\"\n",
    "messages = pd.read_excel(open(file,'rb'), sheetname='yelp_labelled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing data points for message : 0\n",
      "The number of missing data points for result  : 0\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of missing data points for message : %d\" % (sum(messages.message.isnull())))\n",
    "print(\"The number of missing data points for result  : %d\" % (sum(messages.result.isnull())))\n",
    "print(messages.result.value_counts() / messages.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>17</th>\n",
       "      <th>1979</th>\n",
       "      <th>20</th>\n",
       "      <th>2007</th>\n",
       "      <th>30</th>\n",
       "      <th>30s</th>\n",
       "      <th>35</th>\n",
       "      <th>...</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yucky</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  100  12  17  1979  20  2007  30  30s  35  ...   years  yellow  yet  \\\n",
       "0   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "1   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "2   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "3   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "4   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "\n",
       "   you  your  yourself  yucky  yum  yummy  zero  \n",
       "0    0     0         0      0    0      0     0  \n",
       "1    0     1         0      0    0      0     0  \n",
       "2    0     0         0      0    0      0     0  \n",
       "3    2     0         0      0    0      0     0  \n",
       "4    0     0         0      0    0      0     0  \n",
       "\n",
       "[5 rows x 1728 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(messages.message, messages.result, random_state=42)\n",
    "vect = CountVectorizer()\n",
    "train_dtm = vect.fit_transform(X_train)\n",
    "test_dtm = vect.transform(X_test)\n",
    "\n",
    "#Take a look at the resulting dataframe for training data\n",
    "pd.DataFrame(train_dtm.toarray(), columns=vect.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building With Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#Create model\n",
    "bnb = BernoulliNB()\n",
    "# fit it to our training set\n",
    "bnb.fit(train_dtm, y_train)\n",
    "# make predictions on test data using test_dtm\n",
    "predictions = bnb.predict(test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Initial Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  71.60%\n",
      "\n",
      "Confusion Matrix : \n",
      " [[80 48]\n",
      " [23 99]]\n",
      "[0 1]\n",
      "Where Score is either 1 (for positive) or 0 (for negative) sentiment.\n"
     ]
    }
   ],
   "source": [
    "# compare predictions to true results\n",
    "print(\"Accuracy of the model is:  {:.2f}%\\n\".format(100 * metrics.accuracy_score(y_test, predictions)))\n",
    "print(\"Confusion Matrix : \\n\", metrics.confusion_matrix(y_test, predictions))\n",
    "print(bnb.classes_)\n",
    "print(\"Where score is either 1 (for positive) or 0 (for negative) sentiment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The misclassification rate is 28% with a sensitivity of 81% and specificity of 62%. At this time this model has a number of false positives and false negatives, ideally we would like to have these values at zero. Our model is pretty good at identifying positive sentiment and negative sentiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using cross validation to increase the accuracy of our model.  Our dataset has balanced classes and there is no reason to believe that our model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of iteration : 76.00\n"
     ]
    }
   ],
   "source": [
    "# Get word counts for all messages in original data set.\n",
    "X = vect.fit_transform(messages.message.values)\n",
    "y = messages.result.values\n",
    "#pd.DataFrame(X.toarray(), columns=vect.get_feature_names())\n",
    "\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# KFold needs row count not a sparse matrix\n",
    "kf = cross_validation.KFold(X.shape[0], n_folds=5, shuffle=False, random_state=None)\n",
    "# list will house the accuracy score and the confusion matrix\n",
    "results = []\n",
    "for train, test in kf:\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    prediction = bnb.fit(X_train, y_train).predict(X_test)\n",
    "    results.append( (metrics.accuracy_score(y_test, prediction),metrics.confusion_matrix(y_test, prediction))  )\n",
    "    \n",
    "print(\"Mean accuracy of iteration : %.2f\" % (100 * np.array([score for score,_ in results]).mean()))\n",
    "\n",
    "# simple function to calculate misclassification, sensitivity\n",
    "# and specificity from confusion matrix\n",
    "def matrix_metrics(matrix):\n",
    "    total       = matrix[0,0] + matrix[0,1] + matrix[1,0] + matrix[1,1]\n",
    "    msclssfctn  = (matrix[0,1] + matrix[1,0])/total\n",
    "    sensitivity = matrix[1,1]/(matrix[1,0] + matrix[1,1])\n",
    "    specificity = matrix[0,0]/(matrix[0,0] + matrix[0,1]) \n",
    "    return msclssfctn * 100, sensitivity * 100, specificity * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model - 1st step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  78.50%\n",
      "\n",
      "Confusion Matrix : \n",
      " [[68 20]\n",
      " [23 89]]\n",
      "\n",
      "Misclassification : 21.50\n",
      "\n",
      "Sensitivity : 79.46\n",
      "\n",
      "Specificity : 77.27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model is:  {:.2f}%\\n\".format(100 * results[0][0]))\n",
    "print(\"Confusion Matrix : \\n\", results[0][1])\n",
    "misclassification, sensitivity, specificity = matrix_metrics(results[0][1])\n",
    "print(\"\\nMisclassification : %.2f\\n\"% (misclassification))\n",
    "print(\"Sensitivity : %.2f\\n\" % (sensitivity))\n",
    "print(\"Specificity : %.2f\\n\" % (specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
