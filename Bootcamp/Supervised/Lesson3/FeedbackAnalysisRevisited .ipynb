{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinkful Bootcamp Course\n",
    "\n",
    "Author: Ian Heaton\n",
    "\n",
    "Email: iheaton@gmail.com\n",
    "\n",
    "Mentor: Nemanja Radojkovic\n",
    "\n",
    "Date: 2017/03/30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "sb.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Naive Bayes Classifier to look at Yelp Feedback "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"/media/ianh/space/ThinkfulData/SentimentSentencesData/yelp_labelled.xlsx\"\n",
    "messages = pd.read_excel(open(file,'rb'), sheetname='yelp_labelled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing data points for message : 0\n",
      "The number of missing data points for result  : 0\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of missing data points for message : %d\" % (sum(messages.message.isnull())))\n",
    "print(\"The number of missing data points for result  : %d\" % (sum(messages.result.isnull())))\n",
    "print(messages.result.value_counts() / messages.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>17</th>\n",
       "      <th>1979</th>\n",
       "      <th>20</th>\n",
       "      <th>2007</th>\n",
       "      <th>30</th>\n",
       "      <th>30s</th>\n",
       "      <th>35</th>\n",
       "      <th>...</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yucky</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  100  12  17  1979  20  2007  30  30s  35  ...   years  yellow  yet  \\\n",
       "0   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "1   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "2   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "3   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "4   0    0   0   0     0   0     0   0    0   0  ...       0       0    0   \n",
       "\n",
       "   you  your  yourself  yucky  yum  yummy  zero  \n",
       "0    0     0         0      0    0      0     0  \n",
       "1    0     1         0      0    0      0     0  \n",
       "2    0     0         0      0    0      0     0  \n",
       "3    2     0         0      0    0      0     0  \n",
       "4    0     0         0      0    0      0     0  \n",
       "\n",
       "[5 rows x 1728 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(messages.message, messages.result, random_state=42)\n",
    "vect = CountVectorizer()\n",
    "train_dtm = vect.fit_transform(X_train)\n",
    "test_dtm = vect.transform(X_test)\n",
    "\n",
    "#Take a look at the resulting dataframe for training data\n",
    "pd.DataFrame(train_dtm.toarray(), columns=vect.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building With Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#Create model\n",
    "bnb = BernoulliNB()\n",
    "# fit it to our training set\n",
    "bnb.fit(train_dtm, y_train)\n",
    "# make predictions on test data using test_dtm\n",
    "predictions = bnb.predict(test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Initial Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  71.60%\n",
      "\n",
      "Confusion Matrix : \n",
      " [[80 48]\n",
      " [23 99]]\n",
      "[0 1]\n",
      "Where score is either 1 (for positive) or 0 (for negative) sentiment.\n"
     ]
    }
   ],
   "source": [
    "# compare predictions to true results\n",
    "print(\"Accuracy of the model is:  {:.2f}%\\n\".format(100 * accuracy_score(y_test, predictions)))\n",
    "print(\"Confusion Matrix : \\n\", confusion_matrix(y_test, predictions))\n",
    "print(bnb.classes_)\n",
    "print(\"Where score is either 1 (for positive) or 0 (for negative) sentiment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The misclassification rate is 28% with a sensitivity of 81% and specificity of 62%. At this time this model has a number of false positives and false negatives, ideally we would like to have these values at zero. Our model is pretty good at identifying positive sentiment and negative sentiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using cross validation to increase the accuracy of our model.  Our dataset has balanced classes and there is no reason to believe that our model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of iteration : 76.00\n"
     ]
    }
   ],
   "source": [
    "# Get word counts for all messages in original data set.\n",
    "X = vect.fit_transform(messages.message.values)\n",
    "y = messages.result.values\n",
    "#pd.DataFrame(X.toarray(), columns=vect.get_feature_names())\n",
    "feature_names = vect.get_feature_names()\n",
    "class_lables = ['negative sentiment', 'positive sentiment']\n",
    "\n",
    "# KFold needs row count not a sparse matrix\n",
    "kf = cross_validation.KFold(X.shape[0], n_folds=5, shuffle=False, random_state=None)\n",
    "# list will house the accuracy score, confusion matrix and report\n",
    "results = []\n",
    "for train, test in kf:\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    prediction = bnb.fit(X_train, y_train).predict(X_test)\n",
    "    results.append( (accuracy_score(y_test, prediction), confusion_matrix(y_test, prediction),\n",
    "                    classification_report(prediction, y_test, target_names=class_lables))  )\n",
    "    \n",
    "print(\"Mean accuracy of iteration : %.2f\" % (100 * np.array([score for score ,_ ,_ in results]).mean()))\n",
    "\n",
    "# simple function to calculate misclassification from confusion matrix\n",
    "def matrix_metrics(matrix):\n",
    "    total       = matrix[0,0] + matrix[0,1] + matrix[1,0] + matrix[1,1]\n",
    "    msclssfctn  = (matrix[0,1] + matrix[1,0])/total\n",
    "    return msclssfctn * 100\n",
    "\n",
    "\n",
    "# Retrieves the most informative features for a binary classifier\n",
    "# with a little help from stack overflow\n",
    "def most_informative_features(vectorizer, classifier, n=5):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "\n",
    "    for coef, feature in topn_class1:\n",
    "        print(\"%d %.4f %s\" % (class_labels[0], coef, feature))\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    for coef, feature in reversed(topn_class2):\n",
    "        print(\"%d %.4f %s\" % (class_labels[1], coef, feature))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model - 1st step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  78.50%\n",
      "\n",
      "Confusion Matrix : \n",
      " [[68 20]\n",
      " [23 89]]\n",
      "\n",
      "Misclassification : 21.50\n",
      "\n",
      "Classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "negative sentiment       0.77      0.75      0.76        91\n",
      "positive sentiment       0.79      0.82      0.81       109\n",
      "\n",
      "       avg / total       0.78      0.79      0.78       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model is:  {:.2f}%\\n\".format(100 * results[0][0]))\n",
    "print(\"Confusion Matrix : \\n\", results[0][1])\n",
    "misclassification = matrix_metrics(results[0][1])\n",
    "print(\"\\nMisclassification : %.2f\\n\"% (misclassification))\n",
    "print('Classification report:\\n', results[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model - 2nd Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  80.00%\n",
      "\n",
      "Confusion Matrix : \n",
      " [[70 19]\n",
      " [21 90]]\n",
      "\n",
      "Misclassification : 20.00\n",
      "\n",
      "Classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "negative sentiment       0.79      0.77      0.78        91\n",
      "positive sentiment       0.81      0.83      0.82       109\n",
      "\n",
      "       avg / total       0.80      0.80      0.80       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model is:  {:.2f}%\\n\".format(100 * results[1][0]))\n",
    "print(\"Confusion Matrix : \\n\", results[1][1])\n",
    "misclassification = matrix_metrics(results[1][1])\n",
    "print(\"\\nMisclassification : %.2f\\n\"% (misclassification))\n",
    "print('Classification report:\\n', results[1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Model - 3rd Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  74.50%\n",
      "\n",
      "Confusion Matrix : \n",
      " [[62 26]\n",
      " [25 87]]\n",
      "\n",
      "Misclassification : 25.50\n",
      "\n",
      "Classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "negative sentiment       0.70      0.71      0.71        87\n",
      "positive sentiment       0.78      0.77      0.77       113\n",
      "\n",
      "       avg / total       0.75      0.74      0.75       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model is:  {:.2f}%\\n\".format(100 * results[2][0]))\n",
    "print(\"Confusion Matrix : \\n\", results[2][1])\n",
    "misclassification  = matrix_metrics(results[2][1])\n",
    "print(\"\\nMisclassification : %.2f\\n\"% (misclassification))\n",
    "print('Classification report:\\n', results[2][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Model - 4th Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  82.50%\n",
      "\n",
      "Confusion Matrix : \n",
      " [[70 13]\n",
      " [22 95]]\n",
      "\n",
      "Misclassification : 17.50\n",
      "\n",
      "Classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "negative sentiment       0.84      0.76      0.80        92\n",
      "positive sentiment       0.81      0.88      0.84       108\n",
      "\n",
      "       avg / total       0.83      0.82      0.82       200\n",
      "\n",
      "\n",
      " Most informative Features\n",
      "\n",
      "0 -6.1181 00\n",
      "0 -6.1181 10\n",
      "0 -6.1181 11\n",
      "0 -6.1181 12\n",
      "0 -6.1181 15\n",
      "0 -6.1181 17\n",
      "0 -6.1181 1979\n",
      "0 -6.1181 30\n",
      "0 -6.1181 30s\n",
      "0 -6.1181 35\n",
      "0 -6.1181 40min\n",
      "0 -6.1181 45\n",
      "0 -6.1181 4ths\n",
      "0 -6.1181 5lb\n",
      "0 -6.1181 85\n",
      "0 -6.1181 90\n",
      "0 -6.1181 99\n",
      "0 -6.1181 accountant\n",
      "0 -6.1181 ache\n",
      "0 -6.1181 acknowledged\n",
      "0 -6.1181 actual\n",
      "0 -6.1181 ahead\n",
      "0 -6.1181 airline\n",
      "0 -6.1181 ala\n",
      "0 -6.1181 albondigas\n",
      "0 -6.1181 allergy\n",
      "0 -6.1181 alone\n",
      "0 -6.1181 although\n",
      "0 -6.1181 angry\n",
      "0 -6.1181 annoying\n",
      "0 -6.1181 anticipated\n",
      "0 -6.1181 anymore\n",
      "0 -6.1181 anytime\n",
      "0 -6.1181 anyways\n",
      "0 -6.1181 apart\n",
      "0 -6.1181 apologize\n",
      "0 -6.1181 apology\n",
      "0 -6.1181 appalling\n",
      "0 -6.1181 apparently\n",
      "0 -6.1181 appealing\n",
      "\n",
      "\n",
      "1 -0.7290 the\n",
      "1 -0.9823 and\n",
      "1 -1.4176 was\n",
      "1 -1.6754 is\n",
      "1 -1.8986 to\n",
      "1 -1.9437 good\n",
      "1 -1.9592 this\n",
      "1 -2.0750 food\n",
      "1 -2.0927 great\n",
      "1 -2.1291 it\n",
      "1 -2.2263 in\n",
      "1 -2.2469 place\n",
      "1 -2.2895 very\n",
      "1 -2.2895 of\n",
      "1 -2.4045 service\n",
      "1 -2.5072 with\n",
      "1 -2.5072 for\n",
      "1 -2.5917 are\n",
      "1 -2.6524 so\n",
      "1 -2.6524 have\n",
      "1 -2.6841 you\n",
      "1 -2.6841 had\n",
      "1 -2.7508 were\n",
      "1 -2.7508 we\n",
      "1 -2.7508 my\n",
      "1 -2.7859 on\n",
      "1 -2.8223 they\n",
      "1 -2.8992 here\n",
      "1 -2.9826 that\n",
      "1 -2.9826 friendly\n",
      "1 -2.9826 delicious\n",
      "1 -2.9826 be\n",
      "1 -3.0271 really\n",
      "1 -3.0736 time\n",
      "1 -3.0736 back\n",
      "1 -3.0736 amazing\n",
      "1 -3.0736 all\n",
      "1 -3.1224 nice\n",
      "1 -3.1224 but\n",
      "1 -3.1224 best\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model is:  {:.2f}%\\n\".format(100 * results[3][0]))\n",
    "print(\"Confusion Matrix : \\n\", results[3][1])\n",
    "misclassification = matrix_metrics(results[3][1])\n",
    "print(\"\\nMisclassification : %.2f\\n\"% (misclassification))\n",
    "print('Classification report:\\n', results[3][2])\n",
    "print(\"\\n Most informative Features\\n\")\n",
    "most_informative_features(vect, bnb, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth Model - 5th Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  64.50%\n",
      "\n",
      "Confusion Matrix : \n",
      " [[84 68]\n",
      " [ 3 45]]\n",
      "\n",
      "Misclassification : 35.50\n",
      "\n",
      "Classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "negative sentiment       0.55      0.97      0.70        87\n",
      "positive sentiment       0.94      0.40      0.56       113\n",
      "\n",
      "       avg / total       0.77      0.65      0.62       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model is:  {:.2f}%\\n\".format(100 * results[4][0]))\n",
    "print(\"Confusion Matrix : \\n\", results[4][1])\n",
    "misclassification = matrix_metrics(results[4][1])\n",
    "print(\"\\nMisclassification : %.2f\\n\"% (misclassification))\n",
    "print('Classification report:\\n', results[4][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models did a good job at identifying positive sentiment. The list of most informative features for the positive class made the most sense when compared to both classes. The real problem with the models lie with the ability to identify negative sentiment. The misclassification percentage ranged from  18 to 36 %; too high. The most informative features for negative sentiment appear to be nothing more than noise.\n",
    "\n",
    "From the list of informative features it appears that the models are seeing noise words as important which is a symptom of overfitting.  Perhaps their are better models at discerning sentiment than Bayes Classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
